{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d1645a",
   "metadata": {},
   "source": [
    "# MFNet Inference â€” Streaming for Very Large Ortho/DSM (No Full-Image Load)\n",
    "\n",
    "This notebook is optimized for **huge rasters** (e.g., 9â€¯GB ortho). It:\n",
    "- Streams tiles from disk using Rasterio **windows** (no full `read()` of entire images)\n",
    "- Uses a **WarpedVRT** to align DSM to the Ortho grid **on the fly** (CRS/resolution/transform)\n",
    "- Normalizes per-tile and runs MFNet inference\n",
    "- Writes predictions **directly** into a tiled GeoTIFF\n",
    "\n",
    "> Default is **no overlap** to minimize memory. Increase `OVERLAP` if you need smoothing (with the tradeoff that overlaps get last-write-wins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2709d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install deps if needed\n",
    "# %pip install rasterio tqdm matplotlib\n",
    "import os, sys, math, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.vrt import WarpedVRT\n",
    "from rasterio.windows import Window\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== USER CONFIG (edit me) ====\n",
    "ORT_H = './data/AMNS/Cropped.tif'   # e.g., 'data/ortho.tif'\n",
    "DSM_H = './data/AMNS/Cropped_DEM.tif'     # e.g., 'data/dsm.tif'\n",
    "\n",
    "# Checkpoint with trained MFNet weights\n",
    "CHECKPOINT = './weights/sam_vit_l_0b3195.pth'  # e.g., 'checkpoints/mfnet_best.pth'\n",
    "\n",
    "# Model hyper-params (edit to match your training)\n",
    "NUM_CLASSES = 6\n",
    "BACKBONE    = 'sam-vit-l'      # per your training\n",
    "DEVICE      = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# ðŸš€ PERFORMANCE OPTIMIZATION FOR LARGE IMAGES\n",
    "# For RTX 4070 (12GB VRAM) with 9GB ortho, consider these optimizations:\n",
    "\n",
    "# âš¡ QUICK TESTING OPTIONS (choose one):\n",
    "\n",
    "# Option A: Spatial crop (process only a small region) - FASTEST for testing\n",
    "USE_CROP = False\n",
    "# CROP_SIZE = 5000  # Process only 5000x5000 pixels from center (~500 tiles, ~1-2 minutes)\n",
    "\n",
    "# Option B: Aggressive downsampling \n",
    "DOWNSAMPLE_FACTOR = 1   # Quarter resolution (was 2) - reduces tiles by 4x\n",
    "\n",
    "# Option C: Larger tiles, no overlap\n",
    "WINDOW_SIZE = 512   # Larger tiles = fewer tiles (was 256)\n",
    "OVERLAP     = 32     # No overlap = 2x speedup (was 32)\n",
    "\n",
    "# For full production run, disable crop and use:\n",
    "# USE_CROP = False\n",
    "# DOWNSAMPLE_FACTOR = 2  \n",
    "# WINDOW_SIZE = 256\n",
    "# OVERLAP = 32\n",
    "\n",
    "# Memory management\n",
    "BATCH_CLEAR_FREQ = 50  # Clear GPU cache every N tiles\n",
    "\n",
    "# Normalization\n",
    "RGB_MEAN = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n",
    "RGB_STD  = np.array([0.5, 0.5, 0.5], dtype=np.float32)\n",
    "\n",
    "# Output\n",
    "crop_suffix = f'_crop{CROP_SIZE}' if USE_CROP else '_fullimage'\n",
    "OUTPUT_TIF = f'prediction{crop_suffix}_ds{DOWNSAMPLE_FACTOR}_ws{WINDOW_SIZE}_ov{OVERLAP}.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4243ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Model Import ====\n",
    "# Adjust these imports to the actual layout of your SSRS repo\n",
    "try:\n",
    "    # Example: from ssrs.models.mfnet import MFNet\n",
    "    from UNetFormer_MMSAM import UNetFormer as MFNet  # <- change if your path differs\n",
    "except Exception as e:\n",
    "    print('âš ï¸ Could not import MFNet with default path. Update the import to match your repo structure.')\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e92567",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_rgb(rgb, mean=RGB_MEAN, std=RGB_STD):\n",
    "    # rgb: (3,h,w)\n",
    "    rgb = rgb.astype(np.float32)\n",
    "    if np.nanmax(rgb) > 1.0:\n",
    "        rgb /= 255.0\n",
    "    return (rgb - mean[:,None,None]) / std[:,None,None]\n",
    "\n",
    "def norm_dsm(dsm):\n",
    "    # dsm: (1,h,w)\n",
    "    x = dsm.astype(np.float32)\n",
    "    mu = np.nanmean(x)\n",
    "    sd = np.nanstd(x) + 1e-6\n",
    "    return (x - mu) / sd\n",
    "\n",
    "\n",
    "def iter_windows(width, height, size=1024, overlap=0):\n",
    "    step = size - overlap\n",
    "    xs = list(range(0, max(width - size, 0) + 1, step))\n",
    "    ys = list(range(0, max(height - size, 0) + 1, step))\n",
    "    \n",
    "    # Handle edge case where image is smaller than window size\n",
    "    if width <= size:\n",
    "        xs = [0]\n",
    "    elif xs[-1] != width - size and width > size:\n",
    "        xs.append(width - size)\n",
    "        \n",
    "    if height <= size:\n",
    "        ys = [0] \n",
    "    elif ys[-1] != height - size and height > size:\n",
    "        ys.append(height - size)\n",
    "    \n",
    "    for y in ys:\n",
    "        for x in xs:\n",
    "            # Ensure window doesn't exceed image bounds\n",
    "            actual_width = min(size, width - x)\n",
    "            actual_height = min(size, height - y)\n",
    "            \n",
    "            # Skip windows that would be too small (edge case handling)\n",
    "            if actual_width < 1 or actual_height < 1:\n",
    "                continue\n",
    "                \n",
    "            yield Window(x, y, actual_width, actual_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc43d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Open datasets with optional cropping and downsampling ====\n",
    "ortho_src = rasterio.open(ORT_H)\n",
    "print(f'Original Ortho: {ortho_src.width} x {ortho_src.height}, bands={ortho_src.count}')\n",
    "\n",
    "# Step 1: Apply spatial cropping if enabled\n",
    "if USE_CROP:\n",
    "    # Calculate crop bounds (center region)\n",
    "    center_x = ortho_src.width // 2\n",
    "    center_y = ortho_src.height // 2\n",
    "    half_crop = CROP_SIZE // 2\n",
    "    \n",
    "    crop_left = max(0, center_x - half_crop)\n",
    "    crop_top = max(0, center_y - half_crop)\n",
    "    crop_right = min(ortho_src.width, center_x + half_crop)\n",
    "    crop_bottom = min(ortho_src.height, center_y + half_crop)\n",
    "    \n",
    "    crop_width = crop_right - crop_left\n",
    "    crop_height = crop_bottom - crop_top\n",
    "    \n",
    "    # Calculate transform for cropped area\n",
    "    crop_transform = ortho_src.transform * ortho_src.transform.translation(crop_left, crop_top)\n",
    "    \n",
    "    print(f'ðŸŽ¯ Cropping to {crop_width} x {crop_height} pixels (center region)')\n",
    "    print(f'   Crop bounds: x={crop_left}-{crop_right}, y={crop_top}-{crop_bottom}')\n",
    "    \n",
    "    # Create cropped VRT\n",
    "    cropped_ortho = WarpedVRT(ortho_src,\n",
    "        crs=ortho_src.crs,\n",
    "        transform=crop_transform,\n",
    "        width=crop_width,\n",
    "        height=crop_height,\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "else:\n",
    "    cropped_ortho = ortho_src\n",
    "    crop_width, crop_height = ortho_src.width, ortho_src.height\n",
    "    crop_transform = ortho_src.transform\n",
    "\n",
    "# Step 2: Apply downsampling\n",
    "if DOWNSAMPLE_FACTOR > 1:\n",
    "    final_width = crop_width // DOWNSAMPLE_FACTOR\n",
    "    final_height = crop_height // DOWNSAMPLE_FACTOR\n",
    "    final_transform = crop_transform * crop_transform.scale(DOWNSAMPLE_FACTOR, DOWNSAMPLE_FACTOR)\n",
    "    \n",
    "    print(f'ðŸ“‰ Downsampling by factor {DOWNSAMPLE_FACTOR}')\n",
    "    print(f'   Final size: {final_width} x {final_height} (was {crop_width} x {crop_height})')\n",
    "    \n",
    "    # Create final downsampled VRT\n",
    "    ortho = WarpedVRT(cropped_ortho,\n",
    "        crs=cropped_ortho.crs,\n",
    "        transform=final_transform,\n",
    "        width=final_width,\n",
    "        height=final_height,\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "else:\n",
    "    ortho = cropped_ortho\n",
    "    final_width, final_height = crop_width, crop_height\n",
    "    final_transform = crop_transform\n",
    "\n",
    "print(f'ðŸŽ¯ Processing Ortho: {ortho.width} x {ortho.height}, bands={ortho.count}')\n",
    "print(f'   Using first 3 bands (RGB) from {ortho.count}-band ortho image')\n",
    "\n",
    "# Estimate processing time\n",
    "estimated_tiles = math.ceil(final_width / (WINDOW_SIZE - OVERLAP)) * math.ceil(final_height / (WINDOW_SIZE - OVERLAP))\n",
    "estimated_time_min = estimated_tiles / 8 / 60  # ~8 tiles/second\n",
    "print(f'ðŸ“Š Estimated: {estimated_tiles} tiles, ~{estimated_time_min:.1f} minutes processing time')\n",
    "\n",
    "# Estimate memory usage\n",
    "estimated_mb = (final_width * final_height * 3 * 4) / (1024 * 1024)  # 4 bytes per float32 pixel\n",
    "print(f'ðŸ’¾ Estimated ortho memory per full read: {estimated_mb:.1f} MB')\n",
    "\n",
    "# Create DSM VRT aligned to the final processing grid\n",
    "DSM_VRT_OPTS = dict(\n",
    "    crs=ortho.crs,\n",
    "    transform=final_transform,\n",
    "    height=final_height,\n",
    "    width=final_width,\n",
    "    resampling=Resampling.bilinear,\n",
    ")\n",
    "\n",
    "dsm_src = rasterio.open(DSM_H)\n",
    "dsm = WarpedVRT(dsm_src, **DSM_VRT_OPTS)\n",
    "print(f'ðŸ—ºï¸  DSM aligned to processing grid: {dsm.width} x {dsm.height}, bands={dsm.count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b450bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Prepare output GeoTIFF (tiled) ====\n",
    "# Create a clean profile (not from VRT) for writing\n",
    "output_profile = {\n",
    "    'driver': 'GTiff',\n",
    "    'dtype': 'uint16',\n",
    "    'count': 1,\n",
    "    'width': ortho.width,\n",
    "    'height': ortho.height,\n",
    "    'crs': ortho.crs,\n",
    "    'transform': ortho.transform,\n",
    "    'tiled': True,\n",
    "    'blockxsize': min(WINDOW_SIZE, ortho.width),\n",
    "    'blockysize': min(WINDOW_SIZE, ortho.height),\n",
    "    'compress': 'lzw',\n",
    "    'bigtiff': 'YES'\n",
    "}\n",
    "\n",
    "if Path(OUTPUT_TIF).exists():\n",
    "    Path(OUTPUT_TIF).unlink()\n",
    "\n",
    "out = rasterio.open(OUTPUT_TIF, 'w', **output_profile)\n",
    "print(f'Output: {OUTPUT_TIF}')\n",
    "print(f'Output dimensions: {output_profile[\"width\"]} x {output_profile[\"height\"]}')\n",
    "print(f'Output blocks: {output_profile[\"blockxsize\"]} x {output_profile[\"blockysize\"]}')\n",
    "print(f'Output transform: {output_profile[\"transform\"]}')\n",
    "print(f'Window size: {WINDOW_SIZE}, Overlap: {OVERLAP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60800f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Load model & weights ====\n",
    "model = MFNet(num_classes=NUM_CLASSES).to(DEVICE).eval()\n",
    "ckpt = torch.load(CHECKPOINT, map_location=DEVICE)\n",
    "state = ckpt.get('model_state', ckpt)\n",
    "missing, unexpected = model.load_state_dict(state, strict=False)\n",
    "print('Missing keys:', missing)\n",
    "print('Unexpected keys:', unexpected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39250cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Streaming inference ====\n",
    "print(f\"Starting inference on {math.ceil(ortho.width/ WINDOW_SIZE)*math.ceil(ortho.height/ WINDOW_SIZE)} tiles...\")\n",
    "print(f\"Image size: {ortho.width} x {ortho.height}, Window size: {WINDOW_SIZE}, Overlap: {OVERLAP}\")\n",
    "print(f\"Device: {DEVICE}, Model loaded: {torch.cuda.is_available()}\")\n",
    "\n",
    "tile_count = 0\n",
    "with torch.no_grad():\n",
    "    pbar = tqdm(total=math.ceil(ortho.width/ WINDOW_SIZE)*math.ceil(ortho.height/ WINDOW_SIZE), desc='Tiles')\n",
    "    \n",
    "    for win in iter_windows(ortho.width, ortho.height, size=WINDOW_SIZE, overlap=OVERLAP):\n",
    "        try:\n",
    "            # Read ortho tile (only first 3 bands: RGB)\n",
    "            rgb = ortho.read([1, 2, 3], window=win, out_dtype='float32')  # (3,h,w)\n",
    "            if rgb.shape[1] == 0 or rgb.shape[2] == 0:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            rgb = norm_rgb(rgb)\n",
    "\n",
    "            # Read DSM tile (already aligned by WarpedVRT)\n",
    "            d = dsm.read(window=win, out_dtype='float32')      # (count,h,w)\n",
    "            if d.ndim == 2:\n",
    "                d = d[None, ...]\n",
    "            # If DSM has more than 1 band, pick the first, else keep (1,h,w)\n",
    "            dsm_tile = d[:1, ...]\n",
    "            dsm_tile = norm_dsm(dsm_tile)\n",
    "\n",
    "            # To torch\n",
    "            rgb_t = torch.from_numpy(rgb).unsqueeze(0).to(DEVICE)\n",
    "            dsm_t = torch.from_numpy(dsm_tile).squeeze(0).unsqueeze(0).to(DEVICE)  # Remove channel dim, add batch dim\n",
    "\n",
    "            # Debug shapes for first tile\n",
    "            if tile_count == 0:\n",
    "                print(f\"First tile shapes - RGB: {rgb_t.shape}, DSM: {dsm_t.shape}\")\n",
    "                print(f\"Window: {win}\")\n",
    "\n",
    "            # Forward pass with RGB and DSM as separate inputs\n",
    "            logits = model(rgb_t, dsm_t)\n",
    "            \n",
    "            # Debug output shape for first tile\n",
    "            if tile_count == 0:\n",
    "                print(f\"Output logits shape: {logits.shape}\")\n",
    "\n",
    "            pred = torch.argmax(logits, dim=1).squeeze(0).cpu().numpy().astype('uint16')\n",
    "\n",
    "            # Write this window\n",
    "            out.write(pred, 1, window=win)\n",
    "            \n",
    "            # Clear GPU memory periodically  \n",
    "            if tile_count % BATCH_CLEAR_FREQ == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                if tile_count > 0:\n",
    "                    print(f\"ðŸ’¾ Cleared GPU cache at tile {tile_count}, VRAM: {torch.cuda.memory_allocated()/1024**3:.1f}GB\")\n",
    "                \n",
    "            tile_count += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing tile {tile_count} at window {win}: {e}\")\n",
    "            print(f\"  Window bounds: {win.col_off}-{win.col_off + win.width}, {win.row_off}-{win.row_off + win.height}\")\n",
    "            print(f\"  Image bounds: 0-{ortho.width}, 0-{ortho.height}\")\n",
    "            import traceback\n",
    "            print(f\"  Full error: {traceback.format_exc()}\")\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "            \n",
    "    pbar.close()\n",
    "\n",
    "# Close files\n",
    "out.close()\n",
    "dsm.close(); dsm_src.close(); ortho.close()\n",
    "print(f'âœ… Done. Processed {tile_count} tiles. Saved: {OUTPUT_TIF}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbeab3f",
   "metadata": {},
   "source": [
    "## ðŸš€ Performance Optimization Guide for RTX 4070 (12GB VRAM)\n",
    "\n",
    "### Quick Settings for Different Scenarios:\n",
    "\n",
    "**ðŸ§ª Fast Testing (2-3 minutes):**\n",
    "```python\n",
    "DOWNSAMPLE_FACTOR = 4  # Quarter resolution\n",
    "WINDOW_SIZE = 256      # Small tiles\n",
    "OVERLAP = 0            # No overlap\n",
    "```\n",
    "\n",
    "**âš¡ Balanced Performance (~10-15 minutes):**\n",
    "```python\n",
    "DOWNSAMPLE_FACTOR = 2  # Half resolution  \n",
    "WINDOW_SIZE = 256      # Medium tiles\n",
    "OVERLAP = 32           # Moderate overlap\n",
    "```\n",
    "\n",
    "**ðŸŽ¯ High Quality (30-60 minutes):**\n",
    "```python\n",
    "DOWNSAMPLE_FACTOR = 1  # Full resolution\n",
    "WINDOW_SIZE = 256      # Small tiles for memory safety\n",
    "OVERLAP = 64           # Good overlap\n",
    "```\n",
    "\n",
    "### Expected Processing Times:\n",
    "- **Original 9GB ortho**: ~2-4 hours (67447 x 72998 pixels)\n",
    "- **Downsampled 2x**: ~15-30 minutes (33723 x 36499 pixels) \n",
    "- **Downsampled 4x**: ~5-10 minutes (16861 x 18249 pixels)\n",
    "\n",
    "### Memory Usage:\n",
    "- **RTX 4070**: 12GB VRAM available\n",
    "- **Model**: ~2-3GB VRAM\n",
    "- **Per tile (256x256)**: ~10-20MB\n",
    "- **Safe concurrent tiles**: 1 (sequential processing)\n",
    "\n",
    "### Tips:\n",
    "- Start with `DOWNSAMPLE_FACTOR = 4` for initial testing\n",
    "- Monitor GPU memory with `nvidia-smi`\n",
    "- If you get OOM errors, reduce `WINDOW_SIZE` to 128\n",
    "- The final prediction can be upsampled back to original resolution if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Optional: Upsample prediction back to original resolution ====\n",
    "if DOWNSAMPLE_FACTOR > 1:\n",
    "    print(f\"ðŸ” Upsampling prediction from {DOWNSAMPLE_FACTOR}x downsampled back to original resolution...\")\n",
    "    \n",
    "    # Read the downsampled prediction\n",
    "    with rasterio.open(OUTPUT_TIF) as pred_ds:\n",
    "        pred_data = pred_ds.read(1)\n",
    "        \n",
    "    # Create upsampled output profile\n",
    "    upsampled_profile = ortho_src.profile.copy()\n",
    "    upsampled_profile.update(\n",
    "        dtype='uint16', count=1,\n",
    "        tiled=True, blockxsize=512, blockysize=512,\n",
    "        compress='lzw', bigtiff='YES'\n",
    "    )\n",
    "    \n",
    "    # Upsample using nearest neighbor (preserves class labels)\n",
    "    upsampled_tif = f'prediction_fullres_from_ds{DOWNSAMPLE_FACTOR}.tif'\n",
    "    \n",
    "    with rasterio.open(upsampled_tif, 'w', **upsampled_profile) as upsampled_ds:\n",
    "        upsampled_data = upsampled_ds.read(\n",
    "            1,\n",
    "            out_shape=(ortho_src.height, ortho_src.width),\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "        \n",
    "        # Write upsampled data\n",
    "        upsampled_ds.write(upsampled_data, 1)\n",
    "    \n",
    "    print(f\"âœ… Upsampled prediction saved: {upsampled_tif}\")\n",
    "    print(f\"Original resolution: {ortho_src.width} x {ortho_src.height}\")\n",
    "else:\n",
    "    print(\"No upsampling needed - already at full resolution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Check Prediction Results ====\n",
    "print(\"ðŸ” Checking prediction file...\")\n",
    "\n",
    "if Path(OUTPUT_TIF).exists():\n",
    "    # Basic file info\n",
    "    file_size_mb = Path(OUTPUT_TIF).stat().st_size / (1024 * 1024)\n",
    "    print(f\"âœ… Prediction file exists: {OUTPUT_TIF}\")\n",
    "    print(f\"ðŸ“ File size: {file_size_mb:.1f} MB\")\n",
    "    \n",
    "    # Read and analyze the prediction\n",
    "    with rasterio.open(OUTPUT_TIF) as pred:\n",
    "        print(f\"ðŸ—ºï¸ Dimensions: {pred.width} x {pred.height}\")\n",
    "        print(f\"ðŸŽ¯ CRS: {pred.crs}\")\n",
    "        print(f\"ðŸ“Š Data type: {pred.dtypes[0]}\")\n",
    "        print(f\"ðŸ”¢ Bands: {pred.count}\")\n",
    "        \n",
    "        # Read the data\n",
    "        prediction_data = pred.read(1)\n",
    "        print(f\"\\nðŸ“ˆ Prediction Statistics:\")\n",
    "        print(f\"   Shape: {prediction_data.shape}\")\n",
    "        print(f\"   Min value: {prediction_data.min()}\")\n",
    "        print(f\"   Max value: {prediction_data.max()}\")\n",
    "        print(f\"   Unique classes: {np.unique(prediction_data)}\")\n",
    "        \n",
    "        # Count pixels per class\n",
    "        unique, counts = np.unique(prediction_data, return_counts=True)\n",
    "        total_pixels = prediction_data.size\n",
    "        print(f\"\\nðŸŽ¨ Class Distribution:\")\n",
    "        for class_id, count in zip(unique, counts):\n",
    "            percentage = (count / total_pixels) * 100\n",
    "            print(f\"   Class {class_id}: {count:,} pixels ({percentage:.1f}%)\")\n",
    "            \n",
    "else:\n",
    "    print(f\"âŒ Prediction file not found: {OUTPUT_TIF}\")\n",
    "    print(\"Make sure inference completed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Visualize Prediction Results ====\n",
    "if Path(OUTPUT_TIF).exists():\n",
    "    print(\"ðŸŽ¨ Creating visualizations...\")\n",
    "    \n",
    "    with rasterio.open(OUTPUT_TIF) as pred:\n",
    "        prediction_data = pred.read(1)\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Plot 1: Raw prediction classes\n",
    "        im1 = axes[0].imshow(prediction_data, cmap='tab10', vmin=0, vmax=NUM_CLASSES-1)\n",
    "        axes[0].set_title(f'Prediction Classes\\n({prediction_data.shape[0]}Ã—{prediction_data.shape[1]} pixels)')\n",
    "        axes[0].set_xlabel('X')\n",
    "        axes[0].set_ylabel('Y')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar1 = plt.colorbar(im1, ax=axes[0], shrink=0.8)\n",
    "        cbar1.set_label('Class ID')\n",
    "        cbar1.set_ticks(range(NUM_CLASSES))\n",
    "        \n",
    "        # Plot 2: Class histogram\n",
    "        unique, counts = np.unique(prediction_data, return_counts=True)\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, NUM_CLASSES))\n",
    "        bars = axes[1].bar(unique, counts, color=[colors[int(u)] for u in unique])\n",
    "        axes[1].set_title('Class Distribution')\n",
    "        axes[1].set_xlabel('Class ID')\n",
    "        axes[1].set_ylabel('Pixel Count')\n",
    "        axes[1].set_xticks(range(NUM_CLASSES))\n",
    "        \n",
    "        # Add percentage labels on bars\n",
    "        total_pixels = prediction_data.size\n",
    "        for bar, count in zip(bars, counts):\n",
    "            height = bar.get_height()\n",
    "            percentage = (count / total_pixels) * 100\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{percentage:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save visualization\n",
    "        viz_filename = OUTPUT_TIF.replace('.tif', '_visualization.png')\n",
    "        plt.savefig(viz_filename, dpi=150, bbox_inches='tight')\n",
    "        print(f\"ðŸ’¾ Visualization saved: {viz_filename}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Optional: Show a zoomed section if image is large\n",
    "        if prediction_data.shape[0] > 500 or prediction_data.shape[1] > 500:\n",
    "            print(\"\\nðŸ” Showing center 256Ã—256 crop for detail:\")\n",
    "            center_y, center_x = prediction_data.shape[0]//2, prediction_data.shape[1]//2\n",
    "            crop_size = 128\n",
    "            crop = prediction_data[center_y-crop_size:center_y+crop_size, \n",
    "                                center_x-crop_size:center_x+crop_size]\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(crop, cmap='tab10', vmin=0, vmax=NUM_CLASSES-1)\n",
    "            plt.title(f'Center Crop Detail ({crop.shape[0]}Ã—{crop.shape[1]} pixels)')\n",
    "            plt.colorbar(label='Class ID')\n",
    "            crop_viz_filename = OUTPUT_TIF.replace('.tif', '_center_crop.png')\n",
    "            plt.savefig(crop_viz_filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"ðŸ’¾ Center crop saved: {crop_viz_filename}\")\n",
    "            plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No prediction file to visualize\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13357d7d",
   "metadata": {},
   "source": [
    "## ðŸ” Other Ways to Check Your Prediction File\n",
    "\n",
    "### 1. **QGIS (Recommended for GIS analysis)**\n",
    "```bash\n",
    "# Open QGIS and drag-drop the prediction file\n",
    "# Or use command line:\n",
    "qgis prediction_crop5000_ds4_ws512_ov0.tif\n",
    "```\n",
    "**Benefits:**\n",
    "- Geographic context with basemaps\n",
    "- Advanced styling and symbology\n",
    "- Measurement tools\n",
    "- Export to other formats\n",
    "\n",
    "### 2. **Command Line Tools**\n",
    "```bash\n",
    "# File information\n",
    "gdalinfo prediction_crop5000_ds4_ws512_ov0.tif\n",
    "\n",
    "# Quick statistics\n",
    "gdalinfo -stats prediction_crop5000_ds4_ws512_ov0.tif\n",
    "\n",
    "# Convert to different format\n",
    "gdal_translate -of PNG prediction_crop5000_ds4_ws512_ov0.tif prediction.png\n",
    "```\n",
    "\n",
    "### 3. **Python (Alternative Visualization)**\n",
    "```python\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Quick preview\n",
    "with rasterio.open('prediction_crop5000_ds4_ws512_ov0.tif') as src:\n",
    "    data = src.read(1)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(data, cmap='tab10')\n",
    "    plt.colorbar(label='Class ID')\n",
    "    plt.title('Prediction Results')\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "### 4. **Web Viewers**\n",
    "- **Drag into Google Earth Pro** (if georeferenced)\n",
    "- **Use GDAL Web Viewer** for quick preview\n",
    "- **Upload to GIS platforms** like ArcGIS Online\n",
    "\n",
    "### ðŸ“Š **What to Look For:**\n",
    "- **Class distribution**: Are all 6 classes present?\n",
    "- **Spatial patterns**: Do predictions make geographic sense?\n",
    "- **Edge effects**: Any artifacts at tile boundaries?\n",
    "- **Data quality**: No missing/corrupt areas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6005892",
   "metadata": {},
   "source": [
    "## ðŸ¢ Building-Specific Analysis Guide\n",
    "\n",
    "The next cells provide comprehensive building detection analysis. Here's what you'll get:\n",
    "\n",
    "### ðŸ“Š **Statistical Analysis:**\n",
    "- **Building coverage percentage** in your area\n",
    "- **Total building area** in mÂ² and kmÂ²\n",
    "- **Number of building clusters** (connected building regions)\n",
    "- **Cluster size statistics** (largest, smallest, average buildings)\n",
    "- **Building density patterns**\n",
    "\n",
    "### ðŸŽ¨ **Visualizations:**\n",
    "1. **All classes with building highlights** (red outlines)\n",
    "2. **Buildings-only binary mask** (red = buildings)\n",
    "3. **Individual building clusters** (colored by cluster)\n",
    "4. **Building density heatmap** (intensity map)\n",
    "5. **Cluster size distribution** (histogram)\n",
    "6. **Cumulative building area** (largest contributors)\n",
    "\n",
    "### ðŸ’¾ **Export Files:**\n",
    "- `*_buildings_only.tif` â†’ Binary mask (1=building, 0=other)\n",
    "- `*_building_footprints.tif` â†’ Buildings with original class IDs\n",
    "- `*_building_analysis.png` â†’ 4-panel visualization\n",
    "- `*_building_stats.png` â†’ Statistical plots\n",
    "\n",
    "### ðŸ”§ **Configuration Required:**\n",
    "**You MUST set the correct building class ID in the next cell!**\n",
    "\n",
    "1. **First**: Run the general analysis (previous cells) to see all class distributions\n",
    "2. **Identify**: Which class ID(s) represent buildings (usually 5-20% of pixels)  \n",
    "3. **Update**: `BUILDING_CLASS_ID = X` in the next cell\n",
    "4. **Run**: Building analysis cells\n",
    "\n",
    "### ðŸ’¡ **Expected Building Percentages by Area Type:**\n",
    "- **Urban areas**: 15-30% building coverage\n",
    "- **Suburban areas**: 5-15% building coverage  \n",
    "- **Rural areas**: 1-5% building coverage\n",
    "- **Dense cities**: 30-50% building coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db88ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Quick Command Line Checks ====\n",
    "if Path(OUTPUT_TIF).exists():\n",
    "    print(\"ðŸ–¥ï¸ Running quick command line checks...\")\n",
    "    \n",
    "    # Check if gdalinfo is available\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['gdalinfo', OUTPUT_TIF], \n",
    "                              capture_output=True, text=True, timeout=30)\n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… GDAL Info:\")\n",
    "            # Show first 20 lines of gdalinfo output\n",
    "            lines = result.stdout.split('\\n')[:20]\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    print(f\"   {line}\")\n",
    "            if len(result.stdout.split('\\n')) > 20:\n",
    "                print(\"   ... (output truncated)\")\n",
    "        else:\n",
    "            print(\"âŒ gdalinfo failed or not available\")\n",
    "            \n",
    "    except (subprocess.TimeoutExpired, FileNotFoundError):\n",
    "        print(\"âŒ gdalinfo not available or timed out\")\n",
    "    \n",
    "    # Alternative: Use rasterio to show similar info\n",
    "    print(f\"\\nðŸ“Š File Summary:\")\n",
    "    with rasterio.open(OUTPUT_TIF) as src:\n",
    "        print(f\"   File: {OUTPUT_TIF}\")\n",
    "        print(f\"   Size: {src.width} x {src.height}\")\n",
    "        print(f\"   Bands: {src.count}\")\n",
    "        print(f\"   Data Type: {src.dtypes[0]}\")\n",
    "        print(f\"   CRS: {src.crs}\")\n",
    "        print(f\"   Bounds: {src.bounds}\")\n",
    "        print(f\"   Resolution: {src.res}\")\n",
    "        \n",
    "        # Quick data peek\n",
    "        sample = src.read(1, window=rasterio.windows.Window(0, 0, min(100, src.width), min(100, src.height)))\n",
    "        print(f\"   Value range: {sample.min()} - {sample.max()}\")\n",
    "        print(f\"   Sample values: {np.unique(sample)[:10]}...\")  # First 10 unique values\n",
    "        \n",
    "else:\n",
    "    print(f\"âŒ Prediction file not found: {OUTPUT_TIF}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Building-Specific Analysis ====\n",
    "if Path(OUTPUT_TIF).exists():\n",
    "    print(\"ðŸ¢ Analyzing Building Predictions...\")\n",
    "    \n",
    "    # !! CONFIGURE YOUR BUILDING CLASS ID(S) HERE !!\n",
    "    # First, run the basic analysis to see which class(es) represent buildings\n",
    "    # Look at the class distribution and identify which class ID(s) are buildings\n",
    "    \n",
    "    BUILDING_CLASS_ID = 1  # ðŸ”§ CHANGE THIS to your building class ID (0-5)\n",
    "    \n",
    "    # Options for different building types:\n",
    "    # BUILDING_CLASS_IDS = [1]        # Single building class\n",
    "    # BUILDING_CLASS_IDS = [1, 2]     # Multiple building types (e.g., residential, commercial)  \n",
    "    # BUILDING_CLASS_IDS = [3, 4, 5]  # If buildings are classes 3, 4, 5\n",
    "    \n",
    "    BUILDING_CLASS_IDS = [BUILDING_CLASS_ID]  # Single building class\n",
    "    \n",
    "    # ðŸ’¡ If you're unsure which class is buildings:\n",
    "    # 1. Run the general prediction analysis first (previous cells)\n",
    "    # 2. Look at the class distribution percentages\n",
    "    # 3. Identify which class(es) likely represent buildings based on:\n",
    "    #    - Reasonable percentage (usually 5-20% for buildings)\n",
    "    #    - Spatial patterns that look like buildings\n",
    "    # 4. Update BUILDING_CLASS_ID above and re-run this analysis\n",
    "    \n",
    "    print(f\"ðŸŽ¯ Building class ID(s): {BUILDING_CLASS_IDS}\")\n",
    "    \n",
    "    with rasterio.open(OUTPUT_TIF) as pred:\n",
    "        prediction_data = pred.read(1)\n",
    "        \n",
    "        # Create building mask (binary: building vs non-building)\n",
    "        building_mask = np.isin(prediction_data, BUILDING_CLASS_IDS)\n",
    "        \n",
    "        # Calculate building statistics\n",
    "        total_pixels = prediction_data.size\n",
    "        building_pixels = np.sum(building_mask)\n",
    "        building_percentage = (building_pixels / total_pixels) * 100\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Building Statistics:\")\n",
    "        print(f\"   Total pixels: {total_pixels:,}\")\n",
    "        print(f\"   Building pixels: {building_pixels:,}\")\n",
    "        print(f\"   Building coverage: {building_percentage:.2f}%\")\n",
    "        \n",
    "        # Estimate building area (if we know pixel resolution)\n",
    "        pixel_area_m2 = abs(pred.res[0] * pred.res[1])  # Square meters per pixel\n",
    "        building_area_m2 = building_pixels * pixel_area_m2\n",
    "        building_area_km2 = building_area_m2 / 1_000_000\n",
    "        \n",
    "        print(f\"   Pixel resolution: {pred.res[0]:.2f}m x {pred.res[1]:.2f}m\")\n",
    "        print(f\"   Building area: {building_area_m2:,.0f} mÂ² ({building_area_km2:.3f} kmÂ²)\")\n",
    "        \n",
    "        # Find building clusters/regions\n",
    "        from scipy import ndimage\n",
    "        labeled_buildings, num_buildings = ndimage.label(building_mask)\n",
    "        \n",
    "        if num_buildings > 0:\n",
    "            # Calculate building cluster statistics\n",
    "            cluster_sizes = []\n",
    "            for i in range(1, num_buildings + 1):\n",
    "                cluster_size = np.sum(labeled_buildings == i)\n",
    "                cluster_sizes.append(cluster_size)\n",
    "            \n",
    "            cluster_sizes = np.array(cluster_sizes)\n",
    "            \n",
    "            print(f\"\\nðŸ˜ï¸ Building Clusters:\")\n",
    "            print(f\"   Number of building clusters: {num_buildings}\")\n",
    "            print(f\"   Largest cluster: {cluster_sizes.max()} pixels ({cluster_sizes.max() * pixel_area_m2:.0f} mÂ²)\")\n",
    "            print(f\"   Smallest cluster: {cluster_sizes.min()} pixels ({cluster_sizes.min() * pixel_area_m2:.0f} mÂ²)\")\n",
    "            print(f\"   Average cluster size: {cluster_sizes.mean():.1f} pixels ({cluster_sizes.mean() * pixel_area_m2:.0f} mÂ²)\")\n",
    "        else:\n",
    "            print(f\"   âŒ No building clusters detected\")\n",
    "            \n",
    "        # Show class distribution for context\n",
    "        unique, counts = np.unique(prediction_data, return_counts=True)\n",
    "        print(f\"\\nðŸ“ˆ Full Class Distribution:\")\n",
    "        class_names = {\n",
    "            0: \"Background/Other\",\n",
    "            1: \"Buildings(?)\",  # Mark uncertain\n",
    "            2: \"Class 2\", \n",
    "            3: \"Class 3\",\n",
    "            4: \"Class 4\", \n",
    "            5: \"Class 5\"\n",
    "        }\n",
    "        \n",
    "        for class_id, count in zip(unique, counts):\n",
    "            percentage = (count / total_pixels) * 100\n",
    "            name = class_names.get(class_id, f\"Class {class_id}\")\n",
    "            is_building = \"ðŸ¢\" if class_id in BUILDING_CLASS_IDS else \"  \"\n",
    "            print(f\"   {is_building} Class {class_id} ({name}): {count:,} pixels ({percentage:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No prediction file found. Run inference first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Building-Focused Visualizations ====\n",
    "if Path(OUTPUT_TIF).exists():\n",
    "    print(\"ðŸŽ¨ Creating building-focused visualizations...\")\n",
    "    \n",
    "    with rasterio.open(OUTPUT_TIF) as pred:\n",
    "        prediction_data = pred.read(1)\n",
    "        building_mask = np.isin(prediction_data, BUILDING_CLASS_IDS)\n",
    "        \n",
    "        # Create comprehensive building visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('Building Detection Analysis', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: All classes with buildings highlighted\n",
    "        im1 = axes[0,0].imshow(prediction_data, cmap='tab10', vmin=0, vmax=NUM_CLASSES-1)\n",
    "        axes[0,0].set_title('All Classes (Buildings Highlighted)')\n",
    "        axes[0,0].set_xlabel('X (pixels)')\n",
    "        axes[0,0].set_ylabel('Y (pixels)')\n",
    "        \n",
    "        # Overlay building outlines\n",
    "        from scipy import ndimage\n",
    "        building_edges = ndimage.binary_erosion(building_mask) ^ building_mask\n",
    "        if np.any(building_edges):\n",
    "            axes[0,0].contour(building_edges, colors='red', linewidths=1.5, alpha=0.8)\n",
    "        \n",
    "        cbar1 = plt.colorbar(im1, ax=axes[0,0], shrink=0.8)\n",
    "        cbar1.set_label('Class ID')\n",
    "        \n",
    "        # Plot 2: Buildings only (binary mask)\n",
    "        building_display = building_mask.astype(float)\n",
    "        building_display[~building_mask] = np.nan  # Transparent non-buildings\n",
    "        \n",
    "        im2 = axes[0,1].imshow(building_display, cmap='Reds', vmin=0, vmax=1)\n",
    "        axes[0,1].set_title('Buildings Only (Binary Mask)')\n",
    "        axes[0,1].set_xlabel('X (pixels)')\n",
    "        axes[0,1].set_ylabel('Y (pixels)')\n",
    "        \n",
    "        cbar2 = plt.colorbar(im2, ax=axes[0,1], shrink=0.8)\n",
    "        cbar2.set_label('Building (1) / Non-building (0)')\n",
    "        \n",
    "        # Plot 3: Building clusters with labels\n",
    "        labeled_buildings, num_buildings = ndimage.label(building_mask)\n",
    "        \n",
    "        if num_buildings > 0:\n",
    "            im3 = axes[1,0].imshow(labeled_buildings, cmap='tab20', vmin=0)\n",
    "            axes[1,0].set_title(f'Building Clusters (n={num_buildings})')\n",
    "            axes[1,0].set_xlabel('X (pixels)')\n",
    "            axes[1,0].set_ylabel('Y (pixels)')\n",
    "            \n",
    "            # Add cluster size annotations for largest clusters\n",
    "            cluster_sizes = []\n",
    "            cluster_centers = []\n",
    "            for i in range(1, min(6, num_buildings + 1)):  # Show top 5 clusters\n",
    "                cluster_pixels = (labeled_buildings == i)\n",
    "                if np.any(cluster_pixels):\n",
    "                    size = np.sum(cluster_pixels)\n",
    "                    cluster_sizes.append(size)\n",
    "                    \n",
    "                    # Find cluster center\n",
    "                    y_coords, x_coords = np.where(cluster_pixels)\n",
    "                    center_y, center_x = np.mean(y_coords), np.mean(x_coords)\n",
    "                    cluster_centers.append((center_x, center_y))\n",
    "                    \n",
    "                    # Annotate largest clusters\n",
    "                    if i <= 3:  # Top 3 clusters\n",
    "                        axes[1,0].annotate(f'{size}px', (center_x, center_y), \n",
    "                                         color='white', fontweight='bold', \n",
    "                                         ha='center', va='center',\n",
    "                                         bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n",
    "        else:\n",
    "            axes[1,0].text(0.5, 0.5, 'No building clusters detected', \n",
    "                          transform=axes[1,0].transAxes, ha='center', va='center', \n",
    "                          fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray'))\n",
    "            axes[1,0].set_title('Building Clusters')\n",
    "        \n",
    "        # Plot 4: Building density heatmap\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        \n",
    "        # Create density map using Gaussian smoothing\n",
    "        density_map = gaussian_filter(building_mask.astype(float), sigma=10)\n",
    "        \n",
    "        im4 = axes[1,1].imshow(density_map, cmap='YlOrRd', vmin=0, vmax=density_map.max())\n",
    "        axes[1,1].set_title('Building Density Heatmap')\n",
    "        axes[1,1].set_xlabel('X (pixels)')\n",
    "        axes[1,1].set_ylabel('Y (pixels)')\n",
    "        \n",
    "        cbar4 = plt.colorbar(im4, ax=axes[1,1], shrink=0.8)\n",
    "        cbar4.set_label('Building Density')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save building analysis\n",
    "        building_viz_file = OUTPUT_TIF.replace('.tif', '_building_analysis.png')\n",
    "        plt.savefig(building_viz_file, dpi=150, bbox_inches='tight')\n",
    "        print(f\"ðŸ’¾ Building analysis saved: {building_viz_file}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Create building summary statistics plot\n",
    "        if num_buildings > 0:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            # Subplot 1: Cluster size distribution\n",
    "            plt.subplot(1, 2, 1)\n",
    "            cluster_sizes = [np.sum(labeled_buildings == i) for i in range(1, num_buildings + 1)]\n",
    "            plt.hist(cluster_sizes, bins=min(20, num_buildings), edgecolor='black', alpha=0.7, color='skyblue')\n",
    "            plt.xlabel('Cluster Size (pixels)')\n",
    "            plt.ylabel('Number of Clusters')\n",
    "            plt.title('Building Cluster Size Distribution')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Subplot 2: Cumulative building area\n",
    "            sorted_sizes = sorted(cluster_sizes, reverse=True)\n",
    "            cumulative_area = np.cumsum(sorted_sizes)\n",
    "            cumulative_percent = (cumulative_area / np.sum(cluster_sizes)) * 100\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(range(1, len(sorted_sizes) + 1), cumulative_percent, marker='o', markersize=3)\n",
    "            plt.xlabel('Cluster Rank (largest to smallest)')\n",
    "            plt.ylabel('Cumulative Building Area (%)')\n",
    "            plt.title('Cumulative Building Coverage')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add 80% line\n",
    "            plt.axhline(y=80, color='red', linestyle='--', alpha=0.7, label='80% threshold')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            cluster_stats_file = OUTPUT_TIF.replace('.tif', '_building_stats.png')\n",
    "            plt.savefig(cluster_stats_file, dpi=150, bbox_inches='tight')\n",
    "            print(f\"ðŸ’¾ Building statistics saved: {cluster_stats_file}\")\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No prediction file found for building analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b6fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Export Building-Only Results ====\n",
    "if Path(OUTPUT_TIF).exists():\n",
    "    print(\"ðŸ’¾ Exporting building-specific results...\")\n",
    "    \n",
    "    with rasterio.open(OUTPUT_TIF) as pred:\n",
    "        prediction_data = pred.read(1)\n",
    "        building_mask = np.isin(prediction_data, BUILDING_CLASS_IDS)\n",
    "        \n",
    "        # Create building-only GeoTIFF (binary: 1=building, 0=non-building)\n",
    "        building_output = OUTPUT_TIF.replace('.tif', '_buildings_only.tif')\n",
    "        \n",
    "        building_profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'dtype': 'uint8',  # Binary data, uint8 is sufficient\n",
    "            'count': 1,\n",
    "            'width': pred.width,\n",
    "            'height': pred.height,\n",
    "            'crs': pred.crs,\n",
    "            'transform': pred.transform,\n",
    "            'compress': 'lzw',\n",
    "            'tiled': True,\n",
    "            'blockxsize': min(512, pred.width),\n",
    "            'blockysize': min(512, pred.height)\n",
    "        }\n",
    "        \n",
    "        with rasterio.open(building_output, 'w', **building_profile) as building_dst:\n",
    "            building_dst.write(building_mask.astype('uint8'), 1)\n",
    "        \n",
    "        print(f\"âœ… Building mask saved: {building_output}\")\n",
    "        \n",
    "        # Create building footprints GeoTIFF (buildings with original class IDs, others = 0)\n",
    "        footprints_output = OUTPUT_TIF.replace('.tif', '_building_footprints.tif')\n",
    "        \n",
    "        building_footprints = prediction_data.copy()\n",
    "        building_footprints[~building_mask] = 0  # Set non-buildings to 0\n",
    "        \n",
    "        with rasterio.open(footprints_output, 'w', **building_profile) as footprints_dst:\n",
    "            footprints_dst.write(building_footprints.astype('uint8'), 1)\n",
    "        \n",
    "        print(f\"âœ… Building footprints saved: {footprints_output}\")\n",
    "        \n",
    "        # Summary of exported files\n",
    "        print(f\"\\nðŸ“ Building Analysis Files Created:\")\n",
    "        print(f\"   ðŸ—ºï¸  Original prediction: {OUTPUT_TIF}\")\n",
    "        print(f\"   ðŸ  Building mask (binary): {building_output}\")\n",
    "        print(f\"   ðŸ¢ Building footprints (with class IDs): {footprints_output}\")\n",
    "        \n",
    "        # Check file sizes\n",
    "        for filepath in [OUTPUT_TIF, building_output, footprints_output]:\n",
    "            if Path(filepath).exists():\n",
    "                size_mb = Path(filepath).stat().st_size / (1024 * 1024)\n",
    "                print(f\"      {Path(filepath).name}: {size_mb:.1f} MB\")\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ Usage Tips:\")\n",
    "        print(f\"   â€¢ Load {building_output} in QGIS for building overlay analysis\")\n",
    "        print(f\"   â€¢ Use {footprints_output} to distinguish building types\")\n",
    "        print(f\"   â€¢ Both files maintain original georeference and can be used in GIS\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No prediction file found for building export.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee39f56",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- For **IRRG ortho** (NIR,R,G), keep the same band order you trained with, or reorder before `norm_rgb`.\n",
    "- If you want overlapped tiles with smoothing, set `OVERLAP>0` and implement feathering. For simplicity (and memory), this notebook uses **last-write-wins** on overlaps.\n",
    "- If your DSM is noisy, consider a **median filter** or **bilateral filter** per tile before `norm_dsm`.\n",
    "- To visualize a small area, use `rasterio.plot.show` on a window or open `OUTPUT_TIF` in QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18facfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Simple upsampling if needed ====\n",
    "if DOWNSAMPLE_FACTOR > 1:\n",
    "    print(f\"To upsample back to original resolution, use:\")\n",
    "    print(f\"gdalwarp -tr {ortho_src.transform[0]} {abs(ortho_src.transform[4])} -r near {OUTPUT_TIF} prediction_fullres.tif\")\n",
    "else:\n",
    "    print(\"Already at full resolution - no upsampling needed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam_adapt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
